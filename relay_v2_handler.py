import tornado.web
import httpx
import time
import uuid
from typing import Optional
from urllib.parse import urljoin
from config import Config
from utils import format_headers_for_log, format_json_body, format_streaming_body
import json
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class RelayV2Handler(tornado.web.RequestHandler):
    """
    Response API åˆ° Chat Completion API é™çº§å¤„ç†å™¨
    
    å°† OpenAI Response API (/responses) è¯·æ±‚è½¬æ¢ä¸º Chat Completion API (/chat/completions) è¯·æ±‚ï¼Œ
    å¹¶å°†å“åº”è½¬æ¢å› Response API æ ¼å¼ã€‚
    """
    
    def initialize(self, config: Config, http_client: httpx.AsyncClient):
        self.config = config
        self.http_client = http_client
        self.request_id = str(uuid.uuid4())[:8]
        self.start_time = time.time()
    
    def _get_client_ip(self) -> str:
        """è·å–å®¢æˆ·ç«¯ IP åœ°å€"""
        x_forwarded_for = self.request.headers.get("X-Forwarded-For")
        if x_forwarded_for:
            return x_forwarded_for.split(",")[0].strip()
        x_real_ip = self.request.headers.get("X-Real-IP")
        if x_real_ip:
            return x_real_ip
        return self.request.remote_ip or "unknown"
    
    def _log_request(self, method: str, backend_url: str, headers: dict, body: Optional[bytes]):
        """è®°å½•è¯·æ±‚æ—¥å¿—"""
        if not self.config.log_enabled:
            return
        
        client_ip = self._get_client_ip()
        log_parts = [
            f"\n{'='*60}",
            f"ğŸ“¥ V2è¯·æ±‚ [{self.request_id}] (Response API -> Chat Completion)",
            f"{'='*60}",
            f"å®¢æˆ·ç«¯: {client_ip}",
            f"æ–¹æ³•: {method}",
            f"åŸå§‹è·¯å¾„: {self.request.path}",
            f"åç«¯URL: {backend_url}",
        ]
        
        if self.config.log_request_headers:
            formatted_headers = format_headers_for_log(headers, self.config.log_mask_sensitive)
            log_parts.append(f"è¯·æ±‚å¤´: {json.dumps(formatted_headers, ensure_ascii=False, indent=2)}")
        
        if self.config.log_request_body and body:
            formatted_body = format_json_body(body, self.config.log_max_body_length)
            log_parts.append(f"è¯·æ±‚ä½“:\n{formatted_body}")
        
        logger.info("\n".join(log_parts))
    
    def _log_response(self, status_code: int, headers: dict, body: Optional[bytes] = None,
                      is_streaming: bool = False, stream_bytes: int = 0):
        """è®°å½•å“åº”æ—¥å¿—"""
        if not self.config.log_enabled:
            return
        
        elapsed_time = (time.time() - self.start_time) * 1000
        
        log_parts = [
            f"\n{'='*60}",
            f"ğŸ“¤ V2å“åº” [{self.request_id}]",
            f"{'='*60}",
            f"çŠ¶æ€ç : {status_code}",
            f"è€—æ—¶: {elapsed_time:.2f}ms",
        ]
        
        if is_streaming:
            log_parts.append(f"ç±»å‹: æµå¼å“åº”")
            log_parts.append(f"ä¼ è¾“å­—èŠ‚: {stream_bytes}")
        else:
            log_parts.append(f"ç±»å‹: æ™®é€šå“åº”")
        
        if self.config.log_response_headers:
            formatted_headers = format_headers_for_log(dict(headers), self.config.log_mask_sensitive)
            log_parts.append(f"å“åº”å¤´: {json.dumps(formatted_headers, ensure_ascii=False, indent=2)}")
        
        if self.config.log_response_body and body:
            if is_streaming:
                formatted_body = format_streaming_body(body, self.config.log_max_body_length)
            else:
                formatted_body = format_json_body(body, self.config.log_max_body_length)
            log_parts.append(f"å“åº”ä½“:\n{formatted_body}")
        
        log_parts.append(f"{'='*60}")
        logger.info("\n".join(log_parts))
    
    def _log_error(self, error_type: str, error_message: str):
        """è®°å½•é”™è¯¯æ—¥å¿—"""
        elapsed_time = (time.time() - self.start_time) * 1000
        logger.error(
            f"\nâŒ V2é”™è¯¯ [{self.request_id}] - {error_type}\n"
            f"   è€—æ—¶: {elapsed_time:.2f}ms\n"
            f"   è¯¦æƒ…: {error_message}"
        )
    
    def set_default_headers(self):
        """è®¾ç½® CORS å¤´"""
        self.set_header("Access-Control-Allow-Origin", "*")
        self.set_header("Access-Control-Allow-Methods", "GET, POST, PUT, DELETE, PATCH, OPTIONS")
        self.set_header("Access-Control-Allow-Headers", "Content-Type, Authorization, X-Requested-With")
        self.set_header("Access-Control-Max-Age", "3600")
    
    async def options(self, *args, **kwargs):
        """å¤„ç† CORS é¢„æ£€è¯·æ±‚"""
        self.set_status(204)
        self.finish()
    
    def _get_backend_url(self) -> str:
        """æ„å»ºåç«¯ URL"""
        path = self.request.path
        query = self.request.query
        
        # æ£€æµ‹ path ä¸­æ˜¯å¦åŒ…å« v1ï¼Œå¦‚æœæœ‰åˆ™æå– v1 ä¹‹åçš„éƒ¨åˆ†
        if '/v1' in path:
            # æ‰¾åˆ° v1 çš„ä½ç½®ï¼Œæå– v1 ä¹‹åçš„è·¯å¾„éƒ¨åˆ†
            v1_index = path.find('/v1')
            path_after_v1 = path[v1_index + 3:]  # +3 è·³è¿‡ '/v1'
            # ç¡®ä¿ backend_base_url ä»¥ / ç»“å°¾æ—¶ä¸ä¼šäº§ç”ŸåŒæ–œæ 
            base_url = self.config.backend_base_url.rstrip('/')
            backend_url = base_url + path_after_v1
        else:
            backend_url = urljoin(self.config.backend_base_url, path)
        
        if query:
            backend_url = f"{backend_url}?{query}"
        
        return backend_url

    def _get_backend_headers(self) -> dict:
        """æ„å»ºåç«¯è¯·æ±‚å¤´"""
        headers = {}
        skip_headers = {'host', 'content-length', 'transfer-encoding', 'connection'}
        
        for name, value in self.request.headers.get_all():
            if name.lower() not in skip_headers:
                if name.lower() == 'authorization' and self.config.backend_api_key:
                    headers[name] = f"Bearer {self.config.backend_api_key}"
                else:
                    headers[name] = value
        
        if 'authorization' not in [h.lower() for h in self.request.headers.keys()]:
            if self.config.backend_api_key:
                headers['Authorization'] = f"Bearer {self.config.backend_api_key}"
        
        return headers
    
    def _convert_response_api_to_chat_completion(self, request_data: dict) -> dict:
        """
        å°† Response API è¯·æ±‚æ ¼å¼è½¬æ¢ä¸º Chat Completion API æ ¼å¼
        
        Response API æ ¼å¼:
        {
            "model": "gpt-4",
            "input": "Hello" | [{"role": "user", "content": "Hello"}],
            "instructions": "You are a helpful assistant.",
            "tools": [...],
            "tool_choice": ...,
            "temperature": 0.7,
            "max_output_tokens": 1000,
            "stream": true/false,
            ...
        }
        
        Chat Completion API æ ¼å¼:
        {
            "model": "gpt-4",
            "messages": [
                {"role": "system", "content": "..."},
                {"role": "user", "content": "..."}
            ],
            "tools": [...],
            "tool_choice": ...,
            "temperature": 0.7,
            "max_tokens": 1000,
            "stream": true/false,
            ...
        }
        """
        chat_request = {}
        
        # å¤åˆ¶æ¨¡å‹åç§°
        if 'model' in request_data:
            model = request_data['model']
            # åº”ç”¨æ¨¡å‹è¦†ç›–
            if self.config.model_override:
                model = self.config.model_override
                logger.info(f"V2æ¨¡å‹è¦†ç›–: {request_data['model']} -> {model}")
            elif (self.config.model_mapping and 
                  isinstance(self.config.model_mapping, dict) and 
                  model in self.config.model_mapping):
                original_model = model
                model = self.config.model_mapping[model]
                logger.info(f"V2æ¨¡å‹æ˜ å°„: {original_model} -> {model}")
            chat_request['model'] = model
        
        # æ„å»º messages æ•°ç»„
        messages = []
        
        # å¤„ç† instructions (è½¬æ¢ä¸º system message)
        if 'instructions' in request_data:
            messages.append({
                "role": "system",
                "content": request_data['instructions']
            })
        
        # å¤„ç† input
        input_data = request_data.get('input', [])
        if isinstance(input_data, str):
            # ç®€å•å­—ç¬¦ä¸²è¾“å…¥
            messages.append({
                "role": "user",
                "content": input_data
            })
        elif isinstance(input_data, list):
            # æ¶ˆæ¯æ•°ç»„è¾“å…¥
            for item in input_data:
                if isinstance(item, dict):
                    # Response API çš„æ¶ˆæ¯æ ¼å¼è½¬æ¢
                    msg = self._convert_input_message(item)
                    if msg:
                        messages.append(msg)
                elif isinstance(item, str):
                    # ç®€å•å­—ç¬¦ä¸²ä½œä¸ºç”¨æˆ·æ¶ˆæ¯
                    messages.append({
                        "role": "user",
                        "content": item
                    })
        
        chat_request['messages'] = messages
        
        # ç›´æ¥å¤åˆ¶çš„å‚æ•°
        copy_params = ['tools', 'tool_choice', 'temperature', 'top_p', 'stream', 
                       'stop', 'presence_penalty', 'frequency_penalty', 'logit_bias',
                       'user', 'seed', 'response_format', 'parallel_tool_calls']
        for param in copy_params:
            if param in request_data:
                chat_request[param] = request_data[param]
        
        # å‚æ•°åç§°è½¬æ¢
        if 'max_output_tokens' in request_data:
            chat_request['max_tokens'] = request_data['max_output_tokens']
        
        return chat_request
    
    def _convert_input_message(self, item: dict) -> Optional[dict]:
        """
        è½¬æ¢ Response API çš„è¾“å…¥æ¶ˆæ¯ä¸º Chat Completion æ¶ˆæ¯æ ¼å¼
        
        Response API æ¶ˆæ¯ç±»å‹:
        - {"type": "message", "role": "user", "content": [...]}
        - {"type": "item_reference", "id": "..."}  // å¼•ç”¨ä¹‹å‰çš„æ¶ˆæ¯
        - ç›´æ¥çš„ message å¯¹è±¡ {"role": "user", "content": "..."}
        """
        item_type = item.get('type')
        
        if item_type == 'message':
            # Response API æ ¼å¼çš„æ¶ˆæ¯
            role = item.get('role', 'user')
            content = item.get('content', [])
            
            if isinstance(content, str):
                return {"role": role, "content": content}
            elif isinstance(content, list):
                # å¤„ç† content æ•°ç»„
                converted_content = self._convert_content_array(content)
                if converted_content:
                    return {"role": role, "content": converted_content}
        
        elif item_type == 'function_call_output':
            # å‡½æ•°è°ƒç”¨ç»“æœ
            return {
                "role": "tool",
                "tool_call_id": item.get('call_id', ''),
                "content": item.get('output', '')
            }
        
        elif item_type is None and 'role' in item:
            # ç›´æ¥çš„æ¶ˆæ¯å¯¹è±¡æ ¼å¼ï¼ˆå…¼å®¹å¤„ç†ï¼‰
            role = item.get('role', 'user')
            content = item.get('content', '')
            
            if isinstance(content, str):
                return {"role": role, "content": content}
            elif isinstance(content, list):
                converted_content = self._convert_content_array(content)
                if converted_content:
                    return {"role": role, "content": converted_content}
        
        return None
    
    def _convert_content_array(self, content_array: list):
        """
        è½¬æ¢ Response API çš„ content æ•°ç»„
        
        Response API content ç±»å‹:
        - {"type": "input_text", "text": "..."}
        - {"type": "input_image", "image_url": "...", "detail": "..."}
        - {"type": "input_audio", ...}
        
        Chat Completion content ç±»å‹:
        - {"type": "text", "text": "..."}
        - {"type": "image_url", "image_url": {"url": "...", "detail": "..."}}
        """
        if not content_array:
            return ""
        
        # æ£€æŸ¥æ˜¯å¦åªæœ‰çº¯æ–‡æœ¬
        all_text = all(
            (isinstance(item, dict) and item.get('type') in ['input_text', 'text']) or 
            isinstance(item, str)
            for item in content_array
        )
        
        if all_text:
            # çº¯æ–‡æœ¬ï¼Œç›´æ¥æ‹¼æ¥
            texts = []
            for item in content_array:
                if isinstance(item, str):
                    texts.append(item)
                elif isinstance(item, dict):
                    texts.append(item.get('text', ''))
            return ''.join(texts)
        
        # æ··åˆå†…å®¹ï¼Œè½¬æ¢ä¸ºæ•°ç»„æ ¼å¼
        converted = []
        for item in content_array:
            if isinstance(item, str):
                converted.append({"type": "text", "text": item})
            elif isinstance(item, dict):
                item_type = item.get('type', '')
                
                if item_type in ['input_text', 'text']:
                    converted.append({"type": "text", "text": item.get('text', '')})
                
                elif item_type in ['input_image', 'image_url']:
                    # å¤„ç†å›¾åƒ
                    if 'image_url' in item:
                        image_data = item['image_url']
                        if isinstance(image_data, str):
                            converted.append({
                                "type": "image_url",
                                "image_url": {"url": image_data}
                            })
                        elif isinstance(image_data, dict):
                            converted.append({
                                "type": "image_url", 
                                "image_url": image_data
                            })
                    elif 'url' in item:
                        converted.append({
                            "type": "image_url",
                            "image_url": {"url": item['url'], "detail": item.get('detail', 'auto')}
                        })
                
                elif item_type == 'output_text':
                    # å¤„ç†è¾“å‡ºæ–‡æœ¬ï¼ˆæ¥è‡ª assistant æ¶ˆæ¯ï¼‰
                    converted.append({"type": "text", "text": item.get('text', '')})
        
        return converted if converted else ""
    
    def _convert_chat_completion_to_response_api(self, chat_response: dict, original_request: dict) -> dict:
        """
        å°† Chat Completion API å“åº”è½¬æ¢ä¸º Response API æ ¼å¼
        
        Chat Completion å“åº”æ ¼å¼:
        {
            "id": "chatcmpl-xxx",
            "object": "chat.completion",
            "created": 1234567890,
            "model": "gpt-4",
            "choices": [{
                "index": 0,
                "message": {"role": "assistant", "content": "Hello!", "tool_calls": [...]},
                "finish_reason": "stop"
            }],
            "usage": {"prompt_tokens": 10, "completion_tokens": 20, "total_tokens": 30}
        }
        
        Response API æ ¼å¼:
        {
            "id": "resp_xxx",
            "object": "response",
            "created_at": 1234567890,
            "status": "completed",
            "model": "gpt-4",
            "output": [{
                "type": "message",
                "id": "msg_xxx",
                "status": "completed",
                "role": "assistant",
                "content": [{"type": "output_text", "text": "Hello!"}]
            }],
            "usage": {"input_tokens": 10, "output_tokens": 20, "total_tokens": 30}
        }
        """
        # ç”Ÿæˆ Response API é£æ ¼çš„ ID
        response_id = f"resp_{chat_response.get('id', str(uuid.uuid4())[:24])}"
        
        # æ„å»ºè¾“å‡º
        output = []
        choices = chat_response.get('choices', [])
        
        for i, choice in enumerate(choices):
            message = choice.get('message', {})
            finish_reason = choice.get('finish_reason', 'stop')
            
            # è½¬æ¢ finish_reason åˆ° status
            if finish_reason == 'stop':
                status = 'completed'
            elif finish_reason == 'tool_calls':
                status = 'completed'
            elif finish_reason == 'length':
                status = 'incomplete'
            elif finish_reason == 'content_filter':
                status = 'failed'
            else:
                status = 'completed'
            
            # æ„å»º content æ•°ç»„
            content = []
            
            # å¤„ç†æ–‡æœ¬å†…å®¹
            if message.get('content'):
                content.append({
                    "type": "output_text",
                    "text": message['content']
                })
            
            # æ„å»ºæ¶ˆæ¯è¾“å‡º
            msg_output = {
                "type": "message",
                "id": f"msg_{uuid.uuid4().hex[:24]}",
                "status": status,
                "role": "assistant",
                "content": content
            }
            output.append(msg_output)
            
            # å¤„ç† tool_calls
            tool_calls = message.get('tool_calls', [])
            for tool_call in tool_calls:
                if tool_call.get('type') == 'function':
                    function_call_output = {
                        "type": "function_call",
                        "id": f"fc_{uuid.uuid4().hex[:24]}",
                        "call_id": tool_call.get('id', ''),
                        "name": tool_call.get('function', {}).get('name', ''),
                        "arguments": tool_call.get('function', {}).get('arguments', '{}'),
                        "status": "completed"
                    }
                    output.append(function_call_output)
        
        # è½¬æ¢ usage
        usage = {}
        if 'usage' in chat_response:
            chat_usage = chat_response['usage']
            usage = {
                "input_tokens": chat_usage.get('prompt_tokens', 0),
                "output_tokens": chat_usage.get('completion_tokens', 0),
                "total_tokens": chat_usage.get('total_tokens', 0)
            }
        
        # æ„å»ºæœ€ç»ˆå“åº”
        response = {
            "id": response_id,
            "object": "response",
            "created_at": chat_response.get('created', int(time.time())),
            "status": "completed",
            "model": chat_response.get('model', original_request.get('model', '')),
            "output": output,
            "usage": usage
        }
        
        return response
    
    def _convert_chat_completion_chunk_to_response_events(self, chunk_data: dict, 
                                                          is_first: bool = False,
                                                          is_last: bool = False) -> list:
        """
        å°† Chat Completion æµå¼ chunk è½¬æ¢ä¸º Response API çš„ SSE äº‹ä»¶
        
        Chat Completion chunk æ ¼å¼:
        {
            "id": "chatcmpl-xxx",
            "object": "chat.completion.chunk",
            "created": 1234567890,
            "model": "gpt-4",
            "choices": [{
                "index": 0,
                "delta": {"role": "assistant", "content": "Hello"},
                "finish_reason": null
            }]
        }
        
        Response API äº‹ä»¶æ ¼å¼:
        - response.created: {"type": "response.created", "response": {...}}
        - response.output_item.added: {"type": "response.output_item.added", ...}
        - response.content_part.added: {"type": "response.content_part.added", ...}
        - response.output_text.delta: {"type": "response.output_text.delta", "delta": "text"}
        - response.output_text.done: {"type": "response.output_text.done", ...}
        - response.output_item.done: {"type": "response.output_item.done", ...}
        - response.completed: {"type": "response.completed", "response": {...}}
        """
        events = []
        response_id = f"resp_{chunk_data.get('id', str(uuid.uuid4())[:24])}"
        
        choices = chunk_data.get('choices', [])
        if not choices:
            return events
        
        choice = choices[0]
        delta = choice.get('delta', {})
        finish_reason = choice.get('finish_reason')
        
        # å¤„ç†æ–‡æœ¬å¢é‡
        if 'content' in delta and delta['content']:
            events.append({
                "type": "response.output_text.delta",
                "output_index": 0,
                "content_index": 0,
                "delta": delta['content']
            })
        
        # å¤„ç† tool_calls å¢é‡
        if 'tool_calls' in delta:
            for tool_call in delta['tool_calls']:
                index = tool_call.get('index', 0)
                if 'function' in tool_call:
                    func = tool_call['function']
                    if 'arguments' in func and func['arguments']:
                        events.append({
                            "type": "response.function_call_arguments.delta",
                            "output_index": index + 1,  # tool calls åœ¨ message ä¹‹å
                            "delta": func['arguments']
                        })
        
        # å¤„ç†å®Œæˆ
        if finish_reason:
            if finish_reason == 'stop':
                events.append({
                    "type": "response.output_text.done",
                    "output_index": 0,
                    "content_index": 0
                })
            elif finish_reason == 'tool_calls':
                events.append({
                    "type": "response.function_call_arguments.done",
                    "output_index": 0
                })
        
        return events
    
    async def post(self, *args, **kwargs):
        """å¤„ç† POST è¯·æ±‚ - ä¸»è¦ç”¨äºåˆ›å»º response"""
        backend_url = self._get_backend_url()
        headers = self._get_backend_headers()
        
        # è§£æåŸå§‹è¯·æ±‚
        try:
            original_request = json.loads(self.request.body) if self.request.body else {}
        except json.JSONDecodeError:
            self.set_status(400)
            self.write({
                "error": {
                    "message": "Invalid JSON in request body",
                    "type": "invalid_request_error",
                    "code": "invalid_json"
                }
            })
            self.finish()
            return
        
        # è½¬æ¢è¯·æ±‚æ ¼å¼
        chat_request = self._convert_response_api_to_chat_completion(original_request)
        body = json.dumps(chat_request, ensure_ascii=False).encode('utf-8')
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æµå¼è¯·æ±‚
        is_streaming = chat_request.get('stream', False)
        
        # è®°å½•è¯·æ±‚æ—¥å¿—
        self._log_request('POST', backend_url, headers, body)
        
        try:
            if is_streaming:
                await self._handle_streaming_response(backend_url, headers, body, original_request)
            else:
                await self._handle_normal_response(backend_url, headers, body, original_request)
        except httpx.TimeoutException as e:
            self._log_error("è¯·æ±‚è¶…æ—¶", str(e))
            self.set_status(504)
            self.write({
                "error": {
                    "message": f"Backend request timeout: {str(e)}",
                    "type": "relay_error",
                    "code": "timeout"
                }
            })
            self.finish()
        except httpx.RequestError as e:
            self._log_error("è¯·æ±‚å¤±è´¥", str(e))
            self.set_status(502)
            self.write({
                "error": {
                    "message": f"Backend request failed: {str(e)}",
                    "type": "relay_error",
                    "code": "backend_error"
                }
            })
            self.finish()
    
    async def _handle_normal_response(self, url: str, headers: dict, body: bytes, original_request: dict):
        """å¤„ç†æ™®é€šï¼ˆéæµå¼ï¼‰å“åº”"""
        response = await self.http_client.request(
            method='POST',
            url=url,
            headers=headers,
            content=body,
        )
        
        self.set_status(response.status_code)
        
        # å¤åˆ¶å“åº”å¤´
        skip_headers = {'transfer-encoding', 'content-length', 'connection', 'content-encoding'}
        response_headers = {}
        for name, value in response.headers.items():
            if name.lower() not in skip_headers:
                self.set_header(name, value)
                response_headers[name] = value
        
        if response.status_code == 200:
            # è½¬æ¢å“åº”æ ¼å¼
            try:
                chat_response = response.json()
                response_api_response = self._convert_chat_completion_to_response_api(
                    chat_response, original_request
                )
                response_body = json.dumps(response_api_response, ensure_ascii=False).encode('utf-8')
            except (json.JSONDecodeError, Exception) as e:
                logger.warning(f"å“åº”è½¬æ¢å¤±è´¥ï¼Œè¿”å›åŸå§‹å“åº”: {e}")
                response_body = response.content
        else:
            response_body = response.content
        
        # è®°å½•å“åº”æ—¥å¿—
        self._log_response(
            status_code=response.status_code,
            headers=response_headers,
            body=response_body,
            is_streaming=False
        )
        
        self.write(response_body)
        self.finish()
    
    async def _handle_streaming_response(self, url: str, headers: dict, body: bytes, original_request: dict):
        """å¤„ç†æµå¼å“åº”"""
        total_bytes = 0
        response_headers = {}
        collected_chunks = []
        
        # ç”¨äºæ”¶é›†å®Œæ•´å“åº”çš„çŠ¶æ€
        accumulated_content = ""
        accumulated_tool_calls = []
        response_id = None
        model_name = None
        created_time = None
        
        try:
            async with self.http_client.stream(
                method='POST',
                url=url,
                headers=headers,
                content=body,
            ) as response:
                self.set_status(response.status_code)
                
                # è®¾ç½® SSE å“åº”å¤´
                self.set_header('Content-Type', 'text/event-stream')
                self.set_header('Cache-Control', 'no-cache')
                self.set_header('Connection', 'keep-alive')
                
                skip_headers = {'transfer-encoding', 'content-length', 'connection', 'content-encoding', 'content-type'}
                for name, value in response.headers.items():
                    if name.lower() not in skip_headers:
                        self.set_header(name, value)
                        response_headers[name] = value
                
                is_first_chunk = True
                buffer = ""
                
                async for chunk in response.aiter_text():
                    buffer += chunk
                    
                    # å¤„ç† SSE æ ¼å¼çš„æ•°æ®
                    while '\n' in buffer:
                        line, buffer = buffer.split('\n', 1)
                        line = line.strip()
                        
                        if not line:
                            continue
                        
                        if line.startswith('data: '):
                            data_content = line[6:]
                            
                            if data_content == '[DONE]':
                                # å‘é€ Response API çš„å®Œæˆäº‹ä»¶
                                done_event = {
                                    "type": "response.completed",
                                    "response": {
                                        "id": response_id or f"resp_{uuid.uuid4().hex[:24]}",
                                        "object": "response",
                                        "created_at": created_time or int(time.time()),
                                        "status": "completed",
                                        "model": model_name or original_request.get('model', ''),
                                        "output": [{
                                            "type": "message",
                                            "id": f"msg_{uuid.uuid4().hex[:24]}",
                                            "status": "completed",
                                            "role": "assistant",
                                            "content": [{"type": "output_text", "text": accumulated_content}] if accumulated_content else []
                                        }]
                                    }
                                }
                                sse_data = f"data: {json.dumps(done_event, ensure_ascii=False)}\n\n"
                                self.write(sse_data)
                                await self.flush()
                                total_bytes += len(sse_data.encode('utf-8'))
                                collected_chunks.append(sse_data.encode('utf-8'))
                                continue
                            
                            try:
                                chunk_data = json.loads(data_content)
                                
                                # ä¿å­˜å…ƒä¿¡æ¯
                                if not response_id:
                                    response_id = f"resp_{chunk_data.get('id', uuid.uuid4().hex[:24])}"
                                if not model_name:
                                    model_name = chunk_data.get('model')
                                if not created_time:
                                    created_time = chunk_data.get('created')
                                
                                # ç´¯ç§¯å†…å®¹
                                choices = chunk_data.get('choices', [])
                                if choices:
                                    delta = choices[0].get('delta', {})
                                    if 'content' in delta and delta['content']:
                                        accumulated_content += delta['content']
                                    if 'tool_calls' in delta:
                                        accumulated_tool_calls.extend(delta['tool_calls'])
                                
                                # å‘é€ç¬¬ä¸€ä¸ª chunk æ—¶ï¼Œå…ˆå‘é€ response.created äº‹ä»¶
                                if is_first_chunk:
                                    created_event = {
                                        "type": "response.created",
                                        "response": {
                                            "id": response_id,
                                            "object": "response",
                                            "created_at": created_time or int(time.time()),
                                            "status": "in_progress",
                                            "model": model_name or original_request.get('model', ''),
                                            "output": []
                                        }
                                    }
                                    sse_data = f"data: {json.dumps(created_event, ensure_ascii=False)}\n\n"
                                    self.write(sse_data)
                                    await self.flush()
                                    total_bytes += len(sse_data.encode('utf-8'))
                                    collected_chunks.append(sse_data.encode('utf-8'))
                                    
                                    # å‘é€ output_item.added äº‹ä»¶
                                    item_added_event = {
                                        "type": "response.output_item.added",
                                        "output_index": 0,
                                        "item": {
                                            "type": "message",
                                            "id": f"msg_{uuid.uuid4().hex[:24]}",
                                            "status": "in_progress",
                                            "role": "assistant",
                                            "content": []
                                        }
                                    }
                                    sse_data = f"data: {json.dumps(item_added_event, ensure_ascii=False)}\n\n"
                                    self.write(sse_data)
                                    await self.flush()
                                    total_bytes += len(sse_data.encode('utf-8'))
                                    collected_chunks.append(sse_data.encode('utf-8'))
                                    
                                    # å‘é€ content_part.added äº‹ä»¶
                                    content_added_event = {
                                        "type": "response.content_part.added",
                                        "output_index": 0,
                                        "content_index": 0,
                                        "part": {
                                            "type": "output_text",
                                            "text": ""
                                        }
                                    }
                                    sse_data = f"data: {json.dumps(content_added_event, ensure_ascii=False)}\n\n"
                                    self.write(sse_data)
                                    await self.flush()
                                    total_bytes += len(sse_data.encode('utf-8'))
                                    collected_chunks.append(sse_data.encode('utf-8'))
                                    
                                    is_first_chunk = False
                                
                                # è½¬æ¢å¹¶å‘é€äº‹ä»¶
                                events = self._convert_chat_completion_chunk_to_response_events(chunk_data)
                                for event in events:
                                    sse_data = f"data: {json.dumps(event, ensure_ascii=False)}\n\n"
                                    self.write(sse_data)
                                    await self.flush()
                                    total_bytes += len(sse_data.encode('utf-8'))
                                    collected_chunks.append(sse_data.encode('utf-8'))
                                    
                            except json.JSONDecodeError:
                                # æ— æ³•è§£æçš„ chunkï¼Œè·³è¿‡
                                continue
                
                # å¤„ç†ç¼“å†²åŒºå‰©ä½™å†…å®¹
                if buffer.strip():
                    if buffer.strip().startswith('data: '):
                        data_content = buffer.strip()[6:]
                        if data_content == '[DONE]':
                            done_event = {"type": "response.completed"}
                            sse_data = f"data: {json.dumps(done_event, ensure_ascii=False)}\n\n"
                            self.write(sse_data)
                            await self.flush()
                            total_bytes += len(sse_data.encode('utf-8'))
                            collected_chunks.append(sse_data.encode('utf-8'))
                
                # è®°å½•å“åº”æ—¥å¿—
                full_response = b''.join(collected_chunks) if self.config.log_response_body else None
                self._log_response(
                    status_code=response.status_code,
                    headers=response_headers,
                    body=full_response,
                    is_streaming=True,
                    stream_bytes=total_bytes
                )
                
        except Exception as e:
            self._log_error("æµå¼å¤„ç†é”™è¯¯", str(e))
            raise
        finally:
            self.finish()
